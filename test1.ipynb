{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP54caaGFSPk63dQrcGaJKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a7482472/Major-project/blob/main/test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy\n",
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "0yd5roWQh87_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3116261b-f68c-4646-892a-e219de7e771b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/920.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.5.0\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBiBxkvGVaN",
        "outputId": "ef9649bf-d753-483f-d5a7-cab2d75988bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.7840 - loss: 0.4913 - val_accuracy: 0.9341 - val_loss: 0.1851\n",
            "Epoch 2/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9233 - loss: 0.2017 - val_accuracy: 0.9450 - val_loss: 0.1299\n",
            "Epoch 3/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9382 - loss: 0.1532 - val_accuracy: 0.9695 - val_loss: 0.0869\n",
            "Epoch 4/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9580 - loss: 0.1155 - val_accuracy: 0.9787 - val_loss: 0.0685\n",
            "Epoch 5/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9625 - loss: 0.1019 - val_accuracy: 0.9751 - val_loss: 0.0730\n",
            "Epoch 6/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9637 - loss: 0.0986 - val_accuracy: 0.9838 - val_loss: 0.0577\n",
            "Epoch 7/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9688 - loss: 0.0908 - val_accuracy: 0.9627 - val_loss: 0.0939\n",
            "Epoch 8/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9662 - loss: 0.0888 - val_accuracy: 0.9746 - val_loss: 0.0641\n",
            "Epoch 9/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9696 - loss: 0.0782 - val_accuracy: 0.9819 - val_loss: 0.0541\n",
            "Epoch 10/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9737 - loss: 0.0697 - val_accuracy: 0.9740 - val_loss: 0.0636\n",
            "Epoch 11/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9758 - loss: 0.0671 - val_accuracy: 0.9825 - val_loss: 0.0539\n",
            "Epoch 12/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9765 - loss: 0.0663 - val_accuracy: 0.9810 - val_loss: 0.0501\n",
            "Epoch 13/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9762 - loss: 0.0648 - val_accuracy: 0.9853 - val_loss: 0.0459\n",
            "Epoch 14/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9782 - loss: 0.0617 - val_accuracy: 0.9817 - val_loss: 0.0473\n",
            "Epoch 15/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9825 - loss: 0.0513 - val_accuracy: 0.9881 - val_loss: 0.0422\n",
            "Epoch 16/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9833 - loss: 0.0522 - val_accuracy: 0.9806 - val_loss: 0.0553\n",
            "Epoch 17/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9825 - loss: 0.0499 - val_accuracy: 0.9753 - val_loss: 0.0648\n",
            "Epoch 18/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0483 - val_accuracy: 0.9815 - val_loss: 0.0537\n",
            "Epoch 19/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9843 - loss: 0.0460 - val_accuracy: 0.9821 - val_loss: 0.0521\n",
            "Epoch 20/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9866 - loss: 0.0440 - val_accuracy: 0.9847 - val_loss: 0.0445\n",
            "Epoch 21/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0453 - val_accuracy: 0.9840 - val_loss: 0.0460\n",
            "Epoch 22/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9843 - loss: 0.0466 - val_accuracy: 0.9793 - val_loss: 0.0621\n",
            "Epoch 23/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9862 - loss: 0.0406 - val_accuracy: 0.9896 - val_loss: 0.0393\n",
            "Epoch 24/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0412 - val_accuracy: 0.9817 - val_loss: 0.0541\n",
            "Epoch 25/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9863 - loss: 0.0393 - val_accuracy: 0.9859 - val_loss: 0.0423\n",
            "Epoch 26/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9868 - loss: 0.0396 - val_accuracy: 0.9879 - val_loss: 0.0431\n",
            "Epoch 27/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9875 - loss: 0.0351 - val_accuracy: 0.9832 - val_loss: 0.0535\n",
            "Epoch 28/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9878 - loss: 0.0368 - val_accuracy: 0.9838 - val_loss: 0.0559\n",
            "Epoch 29/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9892 - loss: 0.0303 - val_accuracy: 0.9844 - val_loss: 0.0493\n",
            "Epoch 30/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9888 - loss: 0.0355 - val_accuracy: 0.9866 - val_loss: 0.0480\n",
            "Epoch 31/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9881 - loss: 0.0380 - val_accuracy: 0.9834 - val_loss: 0.0501\n",
            "Epoch 32/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0273 - val_accuracy: 0.9849 - val_loss: 0.0487\n",
            "Epoch 33/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0271 - val_accuracy: 0.9847 - val_loss: 0.0521\n",
            "Epoch 34/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0246 - val_accuracy: 0.9876 - val_loss: 0.0497\n",
            "Epoch 35/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9896 - loss: 0.0315 - val_accuracy: 0.9857 - val_loss: 0.0501\n",
            "Epoch 36/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0218 - val_accuracy: 0.9829 - val_loss: 0.0551\n",
            "Epoch 37/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0261 - val_accuracy: 0.9795 - val_loss: 0.0720\n",
            "Epoch 38/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0220 - val_accuracy: 0.9808 - val_loss: 0.0668\n",
            "Epoch 39/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9926 - loss: 0.0211 - val_accuracy: 0.9859 - val_loss: 0.0569\n",
            "Epoch 40/40\n",
            "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9912 - loss: 0.0254 - val_accuracy: 0.9872 - val_loss: 0.0513\n",
            "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
            "Accuracy: 0.9938\n",
            "Precision: 0.9967\n",
            "Recall: 0.9950\n",
            "F1 Score: 0.9959\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import ConvLSTM2D, Dense, Flatten, Dropout, Input\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from skfuzzy import control as ctrl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data(csv_file, time_steps=10):\n",
        "    data = pd.read_csv(csv_file)\n",
        "    features = data[['heart_rate', 'blood_pressure', 'oxygen_saturation', 'respiratory_rate', 'temperature']].values\n",
        "    labels = data['Label'].values\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(features) - time_steps):\n",
        "        X.append(features[i:i + time_steps])\n",
        "        y.append(labels[i + time_steps - 1])  # Label for the end of each sequence\n",
        "\n",
        "    # Reshape X for ConvLSTM2D input\n",
        "    X = np.array(X).reshape(-1, time_steps, 5, 1, 1)  # time_steps, features, 1x1 spatial grid\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "# Load data\n",
        "csv_file = '/content/CVD_Vital_SIgns.csv'  # Update with the correct path if necessary\n",
        "X, y = load_data(csv_file)\n",
        "\n",
        "# Build ConvLSTM2D model\n",
        "def build_conv_lstm_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        ConvLSTM2D(filters=256, kernel_size=(1, 1), activation='relu', return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        ConvLSTM2D(filters=128, kernel_size=(1, 1), activation='relu', return_sequences=False),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define model input shape based on X\n",
        "input_shape = (X.shape[1], X.shape[2], 1, 1)  # (time_steps, features, 1, 1)\n",
        "model = build_conv_lstm_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=40, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Define fuzzy logic system\n",
        "data_variance = ctrl.Antecedent(np.arange(0, 1.1, 0.2), 'data_variance')  # Coarser granularity\n",
        "anomaly_threshold = ctrl.Consequent(np.arange(0, 1.1, 0.2), 'anomaly_threshold')\n",
        "\n",
        "# Define shifted and overlapping fuzzy membership functions\n",
        "data_variance['low'] = fuzz.trimf(data_variance.universe, [0, 0.4, 0.8])  # Covers almost entire range\n",
        "data_variance['medium'] = fuzz.trimf(data_variance.universe, [0.2, 0.6, 1])\n",
        "data_variance['high'] = fuzz.trimf(data_variance.universe, [0.5, 0.9, 1.1])  # Slightly out of bounds\n",
        "\n",
        "anomaly_threshold['low'] = fuzz.trimf(anomaly_threshold.universe, [0.3, 0.6, 1.1])\n",
        "anomaly_threshold['medium'] = fuzz.trimf(anomaly_threshold.universe, [0, 0.5, 1.1])\n",
        "anomaly_threshold['high'] = fuzz.trimf(anomaly_threshold.universe, [0, 0.3, 0.8])\n",
        "\n",
        "# Introduce deliberately conflicting rules\n",
        "rule1 = ctrl.Rule(data_variance['low'], anomaly_threshold['high'])\n",
        "rule2 = ctrl.Rule(data_variance['medium'], anomaly_threshold['low'])\n",
        "rule3 = ctrl.Rule(data_variance['high'], anomaly_threshold['low'])\n",
        "rule4 = ctrl.Rule(data_variance['low'] & data_variance['medium'], anomaly_threshold['medium'])\n",
        "rule5 = ctrl.Rule(data_variance['medium'] | data_variance['high'], anomaly_threshold['high'])\n",
        "\n",
        "# Create control system and simulation\n",
        "anomaly_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5])\n",
        "anomaly_sim = ctrl.ControlSystemSimulation(anomaly_ctrl)\n",
        "\n",
        "# Function to adjust thresholds based on historical variance\n",
        "def adjust_threshold(predictions, historical_variance):\n",
        "    adjusted_thresholds = []\n",
        "    for variance in historical_variance:\n",
        "        anomaly_sim.input['data_variance'] = variance\n",
        "        anomaly_sim.compute()\n",
        "        adjusted_thresholds.append(anomaly_sim.output['anomaly_threshold'])\n",
        "    return np.array(adjusted_thresholds)\n",
        "\n",
        "# After model predictions\n",
        "predictions = model.predict(X)\n",
        "historical_variance = np.var(X, axis=(1, 2, 3))  # Variance per sample\n",
        "adjusted_thresholds = adjust_threshold(predictions.flatten(), historical_variance)\n",
        "predictions_flat = predictions.flatten()\n",
        "adjusted_thresholds = adjusted_thresholds.flatten()\n",
        "\n",
        "# Ensure adjusted_thresholds matches predictions_flat length\n",
        "adjusted_thresholds = adjusted_thresholds[:len(predictions_flat)]\n",
        "\n",
        "# Convert predictions to binary labels based on degraded thresholds\n",
        "binary_predictions = (predictions_flat > adjusted_thresholds).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred, y_pred_prob):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "evaluate_model(y, binary_predictions, predictions_flat)\n"
      ]
    }
  ]
}